{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9kzw1jcIq_A"
      },
      "source": [
        "# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ6 –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É \"–¢–µ–æ—Ä–∏—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è\".\n",
        "–í—ã–ø–æ–ª–Ω–∏–ª–∏ —Å—Ç—É–¥–µ–Ω—Ç–∫–∏:\n",
        "–ñ—É—Ä–∞–≤—Å–∫–∞—è –ï–ª–∏–∑–∞–≤–µ—Ç–∞ –≥—Ä—É–ø–ø–∞ 6404-010302D –∏ –¢–µ–ø–ª—è–∫–æ–≤–∞ –Æ–ª–∏—è –≥—Ä—É–ø–ø–∞ 6403-010302D.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "zNvpAEYiIoby"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from itertools import product\n",
        "from itertools import combinations\n",
        "import math\n",
        "import random\n",
        "from operator import itemgetter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaR7XJeEIuQz"
      },
      "source": [
        "# 6.1 –ù–∞–ø–∏—Å–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–¥–∞ (7,4) —Å –ø–æ—Ä–æ–∂–¥–∞—é—â–∏–º –º–Ω–æ–≥–æ—á–ª–µ–Ω–æ–º ùëî(ùë•)=1+ùë•2+ùë•3, –∏—Å–ø—Ä–∞–≤–ª—è—é—â–µ–≥–æ –æ–¥–Ω–æ–∫—Ä–∞—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏ –∏ –ø—Ä–æ–≤–µ—Å—Ç–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —ç—Ç–æ–≥–æ –∫–æ–¥–∞ –¥–ª—è –æ–¥–Ω–æ-, –¥–≤—É—Ö- –∏ —Ç—Ä—ë—Ö–∫—Ä–∞—Ç–Ω—ã—Ö –æ—à–∏–±–æ–∫."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def coding_with_errors(generator_poly, word_length, error_count):\n",
        "    message = np.random.randint(0, 2, word_length, dtype=int)\n",
        "    print(\"–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ:\", message)\n",
        "\n",
        "    encoded = np.polymul(message, generator_poly) % 2\n",
        "    error_positions = set()\n",
        "\n",
        "    while len(error_positions) < error_count:\n",
        "        error_positions.add(random.randint(0, len(encoded) - 1))\n",
        "\n",
        "    for pos in error_positions:\n",
        "        encoded[pos] ^= 1\n",
        "\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "XMYaShmQj2jj"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_this_err(error_vector, max_error_size):\n",
        "    trimmed_error = np.trim_zeros(error_vector, trim='fb')\n",
        "    return 0 < len(trimmed_error) <= max_error_size"
      ],
      "metadata": {
        "id": "2Y725lLVj7Fc"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "2dgyQrDNUtOb"
      },
      "outputs": [],
      "source": [
        "def decoding(generator_poly, max_error_size, received_word, is_packet_error):\n",
        "    word_length = len(received_word)\n",
        "    syndrome = np.polydiv(received_word, generator_poly)[1] % 2\n",
        "\n",
        "    for i in range(word_length):\n",
        "        error_poly = np.zeros(word_length, dtype=int)\n",
        "        error_poly[word_length - i - 1] = 1\n",
        "\n",
        "        shifted_syndrome = np.polymul(syndrome, error_poly) % 2\n",
        "        residual_syndrome = np.polydiv(shifted_syndrome, generator_poly)[1] % 2\n",
        "\n",
        "        if is_packet_error and is_this_err(residual_syndrome, max_error_size):\n",
        "            corrected_word = correct_errors(received_word, residual_syndrome, generator_poly, word_length, i)\n",
        "            return corrected_word\n",
        "\n",
        "        if not is_packet_error and sum(residual_syndrome) <= max_error_size:\n",
        "            corrected_word = correct_errors(received_word, residual_syndrome, generator_poly, word_length, i)\n",
        "            return corrected_word\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_errors(received_word, syndrome, generator_poly, word_length, index):\n",
        "    error_poly = np.zeros(word_length, dtype=int)\n",
        "    error_poly[index - 1] = 1\n",
        "\n",
        "    correction_poly = np.polymul(error_poly, syndrome) % 2\n",
        "    corrected_word = (np.polyadd(received_word, correction_poly)) % 2\n",
        "\n",
        "    quotient = np.polydiv(corrected_word, generator_poly)[0] % 2\n",
        "    padding = [0] * (len(generator_poly) - len(quotient))\n",
        "    return np.concatenate([padding, quotient])"
      ],
      "metadata": {
        "id": "HctXfCwtlYuO"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 7\n",
        "k = 3\n",
        "t = 1\n",
        "g1 = np.array([1, 1, 0, 1])\n",
        "print(f'g1 = {g1}\\n')\n",
        "\n",
        "for i in range(1, 4):\n",
        "    print(\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫:\", i)\n",
        "    u = coding_with_errors(g1, 4, i)\n",
        "    decoded = decoding(g1, t, u, False)\n",
        "    print(f'–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: {decoded}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fh9qtJwjy1l",
        "outputId": "3ea13682-560f-42ee-9cc3-09afd259bdbd"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "g1 = [1 1 0 1]\n",
            "\n",
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫: 1\n",
            "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: [0 1 1 1]\n",
            "–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: [0. 1. 1. 0.]\n",
            "\n",
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫: 2\n",
            "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: [0 0 1 1]\n",
            "–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: [0. 0. 0. 1.]\n",
            "\n",
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫: 3\n",
            "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: [0 0 0 1]\n",
            "–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: [0. 0. 0. 1.]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3R4C9NqIvS2"
      },
      "source": [
        "# 6.2 –ù–∞–ø–∏—Å–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–¥–∞ (15,9) —Å –ø–æ—Ä–æ–∂–¥–∞—é—â–∏–º –º–Ω–æ–≥–æ—á–ª–µ–Ω–æ–º ùëî(ùë•)=1+ùë•3+ùë•4+ùë•5+ùë•6, –∏—Å–ø—Ä–∞–≤–ª—è—é—â–µ–≥–æ –ø–∞–∫–µ—Ç—ã –æ—à–∏–±–æ–∫ –∫—Ä–∞—Ç–Ω–æ—Å—Ç–∏ 3 –∏ –ø—Ä–æ–≤–µ—Å—Ç–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —ç—Ç–æ–≥–æ –∫–æ–¥–∞ –¥–ª—è –ø–∞–∫–µ—Ç–æ–≤ –æ—à–∏–±–æ–∫ –¥–ª–∏–Ω—ã 1, 2, 3 –∏ 4. –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –ø–∞–∫–µ—Ç –æ—à–∏–±–æ–∫ –¥–ª–∏–Ω—ã t –Ω–µ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –≤—Å–µ —Ä–∞–∑—Ä—è–¥—ã –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö —ç—Ç–æ–≥–æ –ø–∞–∫–µ—Ç–∞ –∏–∑–º–µ–Ω—è—Ç—Å—è (—Å–º. –ª–µ–∫—Ü–∏–∏).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pack_error(word_length, error_size):\n",
        "    error_vector = np.zeros(word_length, dtype=int)\n",
        "    start_index = random.randint(0, word_length - 1)\n",
        "    wrap_offset = 0\n",
        "\n",
        "    for i in range(error_size):\n",
        "        if start_index + i == word_length:\n",
        "            start_index = 0\n",
        "            wrap_offset = i\n",
        "\n",
        "        error_vector[start_index + i - wrap_offset] = 1 if i % 2 == 0 else random.randint(0, 1)\n",
        "\n",
        "    print(\"–û—à–∏–±–∫–∞:\", error_vector)\n",
        "    return error_vector"
      ],
      "metadata": {
        "id": "dmHQueJyj6H0"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def coding_with_pack_error(generator_poly, word_length, error_size):\n",
        "    message = np.random.randint(0, 2, word_length, dtype=int)\n",
        "    print(\"–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ:\", message)\n",
        "\n",
        "    encoded = np.polymul(message, generator_poly) % 2\n",
        "    return (encoded + get_pack_error(len(encoded), error_size)) % 2"
      ],
      "metadata": {
        "id": "F2lM4D-kj9eN"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Y50MpZUdRRCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ce7ace-b92c-44f2-a6f7-1db0a423f100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "g2 = [1 1 1 1 0 0 1]\n",
            "\n",
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫: 1\n",
            "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: [0 1 1 1 0 1 0 0 0]\n",
            "–û—à–∏–±–∫–∞: [0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: [1. 0. 1. 1. 1. 1. 0. 0.]\n",
            "\n",
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫: 2\n",
            "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: [1 1 1 0 0 1 0 0 0]\n",
            "–û—à–∏–±–∫–∞: [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: [1. 1. 1. 0. 0. 1. 0. 0. 0.]\n",
            "\n",
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫: 3\n",
            "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: [0 1 1 0 1 0 0 1 1]\n",
            "–û—à–∏–±–∫–∞: [0 0 0 0 0 1 1 1 0 0 0 0 0 0]\n",
            "–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: [1. 1. 0. 1. 0. 1. 0. 1.]\n",
            "\n",
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫: 4\n",
            "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: [0 0 0 1 0 0 1 0 1]\n",
            "–û—à–∏–±–∫–∞: [0 0 1 1 1 1 0 0 0 0 0 0]\n",
            "–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: [0. 1. 0. 1. 1. 0. 1.]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n2 = 15\n",
        "k2 = 9\n",
        "t2 = 3\n",
        "g2 = np.array([1, 1, 1, 1, 0, 0, 1])\n",
        "print(f'g2 = {g2}\\n')\n",
        "\n",
        "for i in range(1, 5):\n",
        "  print(\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫:\", i)\n",
        "  u = coding_with_pack_error(g2, 9, i)\n",
        "  decoded = decoding(g2, i, u, True)\n",
        "  print(f'–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: {decoded}\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}